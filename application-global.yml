/projectPath: 
#该配置文件用于配置全局变量
global:
  ip: 192.168.23.177  #本机以太网ip地址，需要手动配置
  eureka:
    host: 192.168.23.177   #eureka服务注册与发现的主机ip
    port: 8761     #启动端口
  #redis服务配置
  redis:
    host: 192.168.23.132  #redis服务所部署的服务器ip
    port: 6382   #redis默认端口
    password:
  activemq:
    broker-url: tcp://192.168.23.112:61616
    user: admin
    password: admin
  
  #规则
  urule:
    project:
      default:
        name: 项目1
 #数据源配置
  datasource:
    name: test  #数据库源名称
    #database-name: db_dcp_dev
    database-name: kylo
    url: 192.168.23.112  #数据库所在的url地址
    port: 3306   #数据库端口
    username: root   #数据库用户名
    password: mysql   #数据库密码
    metastore:
      driver: org.postgresql.Driver
      url: jdbc:postgresql://192.168.23.116:20051/hivemeta?socketTimeout=60
      username: hive   #数据库用户名
      password: HiveUser@   #数据库密码
      
  #中心配置模块
  ace-center:
    server:
      port: 8761   #启动端口
  #服务鉴权模块
  ace-auth-server:
    server:
      port: 9777   #启动端口
  #管理模块
  ace-admin:
    server:
      port: 8762   #启动端口
  #网关服务配置
  ace-gate-server:
    server:
      port: 8767   #tomcat服务器启动端口
  
  #数字字典ace-dict模块
  ace-dict:
    server:
      port: 9992
  
  dsg-datalake:
    url: http://192.168.23.112:8400
    user: dladmin
    password: chenmin
  dsg-datalake-agent:
    server:
      port: 10001
      maxHttpHeaderSize: 10240000
  dsg-datalake-feed:
    server:
      port: 10002

  neo4j:
    server:
      port: 10007
    user: neo4j
    password: neo4j123
    url: bolt://192.168.23.177:7687
    queue: neo4j-queue-dcp
  metadata2:
    server:
      port: 10008

  target:
    server:
      port: 10009
    project:
      default: dsg_default_project 

  dsg-kafka-sync:
    server:
      port: 10010
  DataMigration:
    server: 
      port: 10012
  essearch:
    server: 
      port: 10013
      Mqpath: essearch.msg
    queue: essearch.msg
    cluster-nodes: 192.168.23.112:9300
  dsg_monitor: 
    server: 
      port: 10014

  hbase:
    master: 192.168.23.111:21300
    zookeeper:
      quorum: 192.168.23.110,192.168.23.111,192.168.23.112
      property:
        clientPort: 24002
      znode:
        parent: /hbase
    columnFamily: cf  #默认列簇
    namespace: dsg01
    dsgcolumnFamily: dsg_meta
    kerberos:
      confDir: /home/dsg/dcp/backend/kafka2hbase/dsg-kafka2hbase/conf
      userPrincipal: chenmin

  kafka:
    consumer:
      topic: ddl01
      max:
        poll:
          records: 100000
        partition:
          fetch:
            bytes: 5000000
      group:
        id: group_kafka2hbase01
    producer:
      servers: 192.168.23.110:21007,192.168.23.111:21007,192.168.23.112:21007
    redisExceptionTopic: topic_redis_exception
    kerberos:
      confDir: /home/dsg/dcp/backend/kafka2hbase/dsg-kafka2hbase/conf
      userPrincipal: chenmin

  hive:
    url: jdbc:hive2://192.168.23.110:24002,192.168.23.111:24002,192.168.23.112:24002/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2;sasl.qop=auth-conf;auth=KERBEROS;principal=hive/hadoop.hadoop.com@HADOOP.COM;user.principal=chenmin;user.keytab=/home/dsg/dcp/backend/kafka2hbase/dsg-kafka2hbase/conf/user.keytab;
    user: hive
    password: HiveUser@
    dbname: dsg01
    securityFlag: true

  
  azkaban:
    url: http://192.168.23.112:8081
    username: azkaban
    password: azkaban
    execute:
      path: /opt/azkaban/azkaban/urule-azkaban-executor
